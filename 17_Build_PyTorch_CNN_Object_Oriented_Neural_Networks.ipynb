{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "17_Build PyTorch CNN - Object Oriented Neural Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyORdoO+MPuJE5c+mZqgVYpA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YinGuoX/Deep_Learning_Pytorch_WithDeeplizard/blob/master/17_Build_PyTorch_CNN_Object_Oriented_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMNNjgKBdBJx"
      },
      "source": [
        "# Building Neural Networks With PyTorch\n",
        "\n",
        "## 项目大纲\n",
        "\n",
        "从我们的深度学习项目的高角度或鸟瞰的角度来看，我们准备了数据，现在，我们准备构建模型。\n",
        "\n",
        "* 准备数据\n",
        "\n",
        "* **建立模型**\n",
        "\n",
        "* 训练模型\n",
        "\n",
        "* 分析模型的结果\n",
        "\n",
        "当说模型时，我们指的是我们的网络。 “模型”和“网络”一词含义相同。 我们希望网络最终要做的是对将图像输入映射到正确的输出类别的函数进行建模或近似。\n",
        "\n",
        "## 快速的面向对象编程回顾\n",
        "\n",
        "当我们编写程序或构建软件时，有两个关键组成部分，代码和数据。 通过面向对象的编程，我们可以围绕对象来定向程序设计和结构。\n",
        "\n",
        "使用类在代码中定义对象。 一个类定义对象的规范或规范，该规范或规范指定该类的每个对象应具有的数据和代码。\n",
        "\n",
        "创建类的对象时，我们将该对象称为类的实例，并且给定类的所有实例都有两个核心组件：\n",
        "\n",
        "* 方法（代码）\n",
        "\n",
        "* 属性（数据）\n",
        "\n",
        "方法代表代码，而属性代表数据，因此方法和属性由类定义。\n",
        "\n",
        "在给定程序中，许多对象（即给定类的实例）可以同时存在，并且所有实例将具有相同的可用属性和相同的可用方法。 从这个角度来看，它们是统一的。\n",
        "\n",
        "相同类的对象之间的区别是对象中每个属性所包含的值。 每个对象都有其自己的属性值。 这些值确定对象的内部状态。 据说每个对象的代码和数据都封装在对象内。\n",
        "\n",
        "让我们构建一个简单的蜥蜴类来演示类如何封装数据和代码："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOniTQwjc_S7"
      },
      "source": [
        "class Lizard: #class declaration\n",
        "    def __init__(self, name): #class constructor (code)\n",
        "        self.name = name #attribute (data)\n",
        "\n",
        "    def set_name(self, name): #method declaration (code)\n",
        "        self.name = name #method implementation (code)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUhaFcMrdxEZ"
      },
      "source": [
        "第一行声明了类并指定了类名，在本例中为Lizard。\n",
        "\n",
        "第二行定义了一个称为类构造函数的特殊方法。 创建类的新实例时，将调用类构造函数。 作为参数，我们具有self和name。\n",
        "\n",
        "self参数使我们能够创建存储或封装在对象内的属性值。 当我们调用此构造函数或任何其他方法时，我们不会传递self参数。 Python会自动为我们执行此操作。\n",
        "\n",
        "调用方可以任意传递任何其他参数的参数值，这些传入方法的值可以在计算中使用，也可以稍后使用self保存和访问。\n",
        "\n",
        "在完成构造函数后，我们可以在此处创建任意数量的专用方法，使调用者可以更改存储在self中的名称值。 我们在这里要做的就是调用方法并为该名称传递一个新值。 让我们看看实际情况。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf6hlKXndu2a",
        "outputId": "d8ddcb21-6cc4-492e-fa12-f83d5d78718b"
      },
      "source": [
        "lizard = Lizard('deep')\n",
        "print(lizard.name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deep\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDl-rDYTd7jq",
        "outputId": "81e49db5-2b47-410a-9a44-0cc2e0c1a53b"
      },
      "source": [
        "lizard.set_name('lizard')\n",
        "print(lizard.name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lizard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCl4G1-JeI84"
      },
      "source": [
        "我们通过指定类名并传递构造函数参数来创建该类的对象实例。 构造函数将接收这些参数，并且构造函数代码将运行以保存传递的名称。\n",
        "\n",
        "然后，我们可以访问名称并进行打印，还可以调用set_name（）方法来更改名称。 一个程序中可以存在多个这些Lizard实例，每个实例将包含自己的数据。\n",
        "\n",
        "从面向对象的角度来看，关于此设置的重要部分是属性和方法被组织并包含在对象中。\n",
        "\n",
        "现在，让我们切换一下齿轮，看看面向对象的编程如何与PyTorch相适应。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oz9LY3meMvR"
      },
      "source": [
        "## 1.PyTorch's torch.nn Package\n",
        "为了在 PyTorch 中构建神经网络，我们使用了 torch.nn 包，这是 PyTorch 的神经网络(nn)库。我们通常这样导入包:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJefyUYod9_6"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyHgdzRVecG6"
      },
      "source": [
        "这允许我们使用nn别名访问神经网络包。所以从现在开始，如果我们说nn，我们的意思是torch.nn. PyTorch的神经网络库包含了构建神经网络所需的所有典型组件。\n",
        "\n",
        "我们构建一个神经网络所需要的主要组件是一个layer，因此，正如我们所料，PyTorch的神经网络库包含了帮助我们构建层的类。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUwecwQCenHp"
      },
      "source": [
        "### 1.1 PyTorch的nn.Module类\n",
        "众所周知，深度神经网络是使用多层构建的。 这就是使网络更深的原因。 神经网络的每一层都有两个主要组成部分：\n",
        "\n",
        "* 转换（代码）\n",
        "\n",
        "* 权重集合（数据）\n",
        "\n",
        "就像生活中的许多事物一样，这一事实使layer成为使用OOP表示为对象的理想对象（OOP是面向对象编程的缩写）。\n",
        "\n",
        "实际上，PyTorch就是这种情况。 在nn包中，有一个名为Module的类，它是所有神经网络模块（包括层）的基类。\n",
        "\n",
        "这意味着PyTorch中的所有层都扩展了nn.Module类，并继承了nn.Module类中所有PyTorch的内置功能。 在OOP中，此概念称为继承。\n",
        "\n",
        "甚至神经网络都扩展了nn.Module类。 这是有道理的，因为神经网络本身可以看作是一个很大的层（如果需要，可以让它随着时间的流逝而沉没）。\n",
        "\n",
        "PyTorch中的神经网络和图层扩展了nn.Module类。 这意味着在PyTorch中构建新层或神经网络时，必须扩展nn.Module类。\n",
        "\n",
        "#### 1.1.1 PyTorch nn.Modules具有forward（）方法\n",
        "当我们将张量作为输入传递到我们的网络时，张量会通过每一层变换向前流动，直到张量到达输出层为止。 张量通过网络向前流动的过程称为前向传播。\n",
        "\n",
        "每一层都有自己的变换（代码），张量向前穿过每一层。所有各层前向传递的组合定义了网络的整体前向传递转换。\n",
        "\n",
        "整体转换的目标是将输入转换或映射到正确的预测输出类，并且在训练过程中，层权重（数据）以使映射调整以使输出更接近正确的预测的方式进行更新。\n",
        "\n",
        "这一切都意味着，每个Pytorch的nn.Module都有一个forward（）方法，因此在构建层和网络时，必须提供forward（）方法的实现。正向传播就是实际的变换。\n",
        "\n",
        "### 1.2 PyTorch的 nn.functional包\n",
        "\n",
        "当我们实现nn.Module子类的forward（）方法时，通常将使用nn.functional包中的函数。 该软件包为我们提供了许多可用于构建图层的神经网络操作。 实际上，许多nn.Module层类都使用nn.functional函数来执行其操作。\n",
        "\n",
        "nn.functional程序包包含方法，这些方法是nn.Module的子类，用于实现其forward（）函数。 稍后，通过查看nn.Conv2d卷积层类的PyTorch源代码，我们可以看到一个示例。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hVzR2t7gSYZ"
      },
      "source": [
        "## 2.Building A Neural Network In PyTorch\n",
        "现在，我们有足够的信息来提供在PyTorch中构建神经网络的概述。 步骤如下：\n",
        "\n",
        "精简版：\n",
        "\n",
        "* 扩展nn.Module基类。\n",
        "\n",
        "* 将layer定义为类属性。\n",
        "\n",
        "* 实现forward（）方法。\n",
        "\n",
        "\n",
        "详细版：\n",
        "\n",
        "* 创建一个扩展nn.Module基类的神经网络类。\n",
        "\n",
        "* 在类构造函数中，使用torch.nn中的预构建图层将网络的图层定义为类属性。\n",
        "\n",
        "* 使用网络的图层属性以及nn.functional API的操作来定义网络的前向传递。\n",
        "\n",
        "### 2.1 扩展PyTorch的nn.Module类\n",
        "\n",
        "就像我们在蜥蜴类示例中所做的一样，让我们​​创建一个简单的类来表示神经网络\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI6gv7qleTsq"
      },
      "source": [
        "class Network:\n",
        "  def __init__(self):\n",
        "    slef.layer = None\n",
        "  def forward(self,t):\n",
        "    t = self.layer(t)\n",
        "    return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04gIq14ZhOv6"
      },
      "source": [
        "这为我们提供了一个简单的网络类，该类在构造函数内部具有单个虚拟层，并为forward函数提供了虚拟实现。\n",
        "\n",
        "forward（）函数的实现采用张量t并使用伪层对其进行转换。 张量转换后，将返回新的张量。\n",
        "\n",
        "这是一个好的开始，但是该类尚未扩展nn.Module类。 要使我们的Network类扩展nn.Module，我们必须做另外两件事：\n",
        "\n",
        "在第1行的括号中指定nn.Module类。\n",
        "\n",
        "在构造函数内部的第3行上插入对超类构造函数的调用。\n",
        "\n",
        "也就是：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk-stcEvhGu7"
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    supper().__init__()\n",
        "    slef.layer = None\n",
        "  def forward(self,t):\n",
        "    t = self.layer(t)\n",
        "    return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jioFihb7hc2w"
      },
      "source": [
        "这些变化将我们的简单神经网络转换为PyTorch神经网络，因为我们现在正在扩展PyTorch的nn.Module基类。\n",
        "\n",
        "这样，我们就完成了！ 现在，我们有了一个Network类，它具有PyTorch nn.Module类的所有功能。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRA8KODKhoI5"
      },
      "source": [
        "### 2.2将网络的层定义为类属性\n",
        "\n",
        "目前，我们的Network类具有单个虚拟层作为属性。 现在让我们用从PyTorch的nn库中为我们预先构建的一些真实图层替换它。 我们正在构建一个CNN，因此我们将使用的两种类型的层是线性层和卷积层。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGK2GERdhYDa"
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6,out_channels=12,kernel_size=5)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features==12*4*4,out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120,out_features=60)\n",
        "    self.fc3 = nn.Linear(in_features==60,out_features=10)\n",
        "\n",
        "  def forward(self,t):\n",
        "    return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJJ3mEMdik1o"
      },
      "source": [
        "好吧。 至此，我们有了一个名为Network的Python类，该类扩展了PyTorch的nn.Module类。 在我们的Network类内部，我们有五个定义为属性的层。 我们有两个卷积层，self.conv1和self.conv2，以及三个线性层，self.fc1，self.fc2，self.out。\n",
        "\n",
        "我们在fc1和fc2中使用了缩写fc，因为线性层也称为完全连接层。 它们还有一个我们可能会听到的叫做“稠密”的名字。 因此，线性，密集和完全连接都是指同一类型的层的所有方法。 PyTorch使用线性这个词，因此使用nn.Linear类名。\n",
        "\n",
        "我们将名称out用作最后一个线性层，因为网络中的最后一层是输出层。\n",
        "\n",
        "我们现在应该对如何开始使用 torch.nn 库在 PyTorch 中构建神经网络有了一个很好的想法。在下一篇文章中，我们将调查层的不同类型的参数，并了解它们是如何选择的。下次见。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbMZPspJib7K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}