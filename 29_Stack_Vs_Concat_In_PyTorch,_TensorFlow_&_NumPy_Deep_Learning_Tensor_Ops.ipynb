{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "29_Stack Vs Concat In PyTorch, TensorFlow & NumPy - Deep Learning Tensor Ops.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN1w6UvIOT36usrPu5XUxoL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YinGuoX/Deep_Learning_Pytorch_WithDeeplizard/blob/master/29_Stack_Vs_Concat_In_PyTorch%2C_TensorFlow_%26_NumPy_Deep_Learning_Tensor_Ops.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X2NaA1YIPld"
      },
      "source": [
        "# Tensor Ops For Deep Learning: Concatenate Vs Stack\n",
        " 在节中，我们将剖析concatenating和stacking张量之间的区别。 我们将看三个示例，一个示例使用PyTorch，一个使用TensorFlow，另一个使用NumPy。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12zbngC7J0mZ"
      },
      "source": [
        "## 1.现有轴与新轴\n",
        "stacking张量和concatenating张量之间的差异可以用一个句子描述：\n",
        "* Concatenating joins a sequence of tensors along an existing axis, and stacking joins a sequence of tensors along a new axis.\n",
        "\n",
        "这就是全部！\n",
        "\n",
        "这是stacking和concatenating之间的区别。 但是，这里的描述有些棘手，因此让我们看一些示例，以了解如何更好地理解这一点。 我们将研究PyTorch，TensorFlow和NumPy中的stacking和concatenating。 我们开始做吧。\n",
        "\n",
        "在大多数情况下，沿着张量的现有轴进行contatenating非常简单。 当我们想沿着新的轴进行衔接时，通常会产生混乱。 为此，我们stacking。 表示stacking的另一种方式是，我们创建一个新轴，然后在该轴上合并。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8bcvnV5Kf07"
      },
      "source": [
        "|Join Method | Where|\n",
        "| :---: | :---: |\n",
        "|Concatenate|Along an existing axis|\n",
        "|Stack|Along a new axis|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGeAyJcyKxF7"
      },
      "source": [
        "因此，请确保我们知道如何为给定张量创建新轴，然后开始stacking和concatenating。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c74E07GwK39y"
      },
      "source": [
        "### 如何在张量中添加或插入轴\n",
        "---\n",
        "为了演示添加轴的想法，我们将使用PyTorch。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRwlEHeaKwxL",
        "outputId": "42556c77-0e34-409e-a03a-c09cd159819c"
      },
      "source": [
        "import torch\n",
        "t1 = torch.tensor([1,1,1])\n",
        "t1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwlCKq2sLGbS"
      },
      "source": [
        "在这里，我们要导入PyTorch并创建一个简单的张量，该张量具有一个长度为3的单轴。 现在，要在PyTorch中向张量添加轴，我们使用unsqueeze（）函数。 请注意，这与压缩相反。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx6jJu_PHjYo",
        "outputId": "5dea39b1-9f41-4193-d688-c171b329782d"
      },
      "source": [
        "t1.unsqueeze(dim=0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh-m7NiOLaCL",
        "outputId": "453ef022-25e3-4390-acb6-c70904512984"
      },
      "source": [
        "t1.unsqueeze(dim=0).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lChGqIUeLVZz"
      },
      "source": [
        "在这里，我们在这个张量的指数零点加一个轴，也就是维度。这给了我们一个形状为1x3的张量。当我们说张量的指数0时，我们指的是张量形状的第一个指数。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUsnelY_LZID"
      },
      "source": [
        "现在，我们还可以在该张量的第二个索引处添加一个轴。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pns0FVFoLNCM",
        "outputId": "874bee46-cf0d-4331-f5e7-aae1336e598d"
      },
      "source": [
        "t1.unsqueeze(dim=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [1],\n",
              "        [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM9wBYanLlOc",
        "outputId": "af0bec4b-92fe-4394-87a5-17c214a14f81"
      },
      "source": [
        "t1.unsqueeze(dim=1).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3RXf_b7LsBT"
      },
      "source": [
        "这给我们提供了一个3 x 1形状的张量。添加这样的轴会更改数据在张量内部的组织方式，但不会更改数据本身。 基本上，我们只是在重塑张量。 通过检查每个形状，我们可以看到这一点。\n",
        "\n",
        "现在，回想一下concatenating和stacking的问题，当我们进行concatenating时，我们将沿着现有轴连接一系列张量。 这意味着我们正在扩展现有轴的长度。\n",
        "\n",
        "当我们stacking时，我们正在创建一个以前不存在的新轴，并且这会在序列中的所有张量上发生，然后沿着这个新序列进行合并。\n",
        "\n",
        "让我们看看如何在PyTorch中完成此操作。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e5bYAJaL_96"
      },
      "source": [
        "## 2.在PyTorch中Stack Vs Cat\n",
        "\n",
        "使用PyTorch，我们用于这些操作的两个函数是stack和cat。 让我们创建一个张量序列。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_7zzSZjLrXr"
      },
      "source": [
        "import torch\n",
        "\n",
        "t1 = torch.tensor([1,1,1])\n",
        "t2 = torch.tensor([2,2,2])\n",
        "t3 = torch.tensor([3,3,3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h15oEfcyMNqy"
      },
      "source": [
        "现在，让我们将它们彼此串联在一起。 请注意，每个张量都有一个轴。 这意味着cat函数的结果也将具有单个轴。 这是因为当我们连接时，我们会沿现有的轴进行连接。 请注意，在此示例中，唯一存在的轴是第一个轴。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqXS-CMiMIYL",
        "outputId": "24546a7c-f9f4-42ab-d139-c8b918a4d302"
      },
      "source": [
        "torch.cat((t1,t2,t3),dim=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 2, 2, 2, 3, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EQZZtkFMyLq"
      },
      "source": [
        "好了，所以我们取了三个单轴张量，每个轴张量的轴长为3，现在我们有了一个单张量，轴长为9。\n",
        "\n",
        "现在，让我们沿着将要插入的新轴stacking这些张量。 我们将在第一个索引处插入一个轴。 请注意，此插入将通过stack()函数在后台隐式发生。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2CGRLsEMsHL",
        "outputId": "72f88143-00c8-45b9-cbea-2796ddae2e72"
      },
      "source": [
        "torch.stack((t1,t2,t3),dim=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1],\n",
              "        [2, 2, 2],\n",
              "        [3, 3, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLqby-riNcGi"
      },
      "source": [
        "这为我们提供了一个形状为3 x 3的新张量。请注意，这三个张量是如何沿着该张量的第一个轴连接的。 请注意，我们还可以显式插入新轴，并直接执行串联。\n",
        "\n",
        "看看这个说法是对的。 让我们通过拉伸所有张量，向它们添加一个长度为1的新轴，然后沿着第一个轴concatenating。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53xR5LTwNTmq",
        "outputId": "ec4042cd-d730-42d6-80b9-70cc84d54eb6"
      },
      "source": [
        "torch.cat((\n",
        "    t1.unsqueeze(0),\n",
        "    t2.unsqueeze(0),\n",
        "    t3.unsqueeze(0),\n",
        "),dim=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1],\n",
              "        [2, 2, 2],\n",
              "        [3, 3, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrmZS0JINyFB"
      },
      "source": [
        "在这个例子中，我们可以看到，我们得到的结果与stack得到的结果相同。但是，对stack的调用要干净得多，因为新的轴插入是由stack函数完成的。\n",
        "\n",
        "* Concatenation happens along an existing axis.\n",
        "\n",
        "请注意，由于当前不存在第二个轴，因此无法沿着第二个轴concatenaing此张量序列，因此在这种情况下，stacking是我们唯一的选择。\n",
        "\n",
        "让我们尝试沿第二个轴stacking。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqbB2Qj7Nti6",
        "outputId": "b8c47afb-6d70-48af-afff-7fa04b2cba3d"
      },
      "source": [
        "torch.stack(\n",
        "(t1,t2,t3),\n",
        "dim=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [1, 2, 3],\n",
              "        [1, 2, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7QFs2JOOMFJ"
      },
      "source": [
        "好的，我们相对于第二个轴叠加，这就是结果。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_McJnvfOITL",
        "outputId": "761df400-a815-4dcb-83d6-4d80950ea0f3"
      },
      "source": [
        "torch.cat(\n",
        "  (  t1.unsqueeze(1),\n",
        "    t2.unsqueeze(1),\n",
        "    t3.unsqueeze(1),)\n",
        "  ,dim=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [1, 2, 3],\n",
              "        [1, 2, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JooIwUG1OfbK"
      },
      "source": [
        "要了解此结果，请回想一下在张量末端插入新轴时的外观。 现在，我们只需要对所有张量执行此操作，就可以沿着第二个轴对它们进行分类。 检查unsqueeze的输出可以帮助使这一点变得可靠。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUe_-TsvOYPq",
        "outputId": "0aa2d7aa-92cb-480c-a150-0c63c1fc4c0c"
      },
      "source": [
        "t1.unsqueeze(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [1],\n",
              "        [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k97MQbTMOkjK",
        "outputId": "5503eedb-73d0-4302-cdee-78baecde2126"
      },
      "source": [
        "t1.unsqueeze(1).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlFXoEEaOl06",
        "outputId": "629747b8-4dd4-4a62-b1bc-51c5846c0b0d"
      },
      "source": [
        "t2.unsqueeze(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2],\n",
              "        [2],\n",
              "        [2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deDe15gdOtTr",
        "outputId": "0e650b15-d8a5-4859-b226-d4e7bdcd85b4"
      },
      "source": [
        "t3.unsqueeze(-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3],\n",
              "        [3],\n",
              "        [3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4G3JEbVO5DZ"
      },
      "source": [
        "## 3.TensorFlow中的Stack Vs Concat\n",
        "现在让我们使用TensorFlow。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ga8jSEtOvgc"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "t1 = tf.constant([1,1,1])\n",
        "t2 = tf.constant([2,2,2])\n",
        "t3 = tf.constant([3,3,3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZvHbSFEPGwJ"
      },
      "source": [
        "在这里，我们导入了TensorFlow并使用tf.constant（）函数创建了三个张量。 现在，让我们将这些张量彼此concatenate。 要在TensorFlow中执行此操作，我们使用tf.concat（）函数，而不是指定dim（如PyTorch），而是指定一个axis。 这两个意思相同。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdc-o-sPPCdK",
        "outputId": "2fa8f717-0974-436b-e7c6-4d2409047d82"
      },
      "source": [
        "tf.concat((t1,t2,t3),axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([1, 1, 1, 2, 2, 2, 3, 3, 3], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TZTD-GjPVeI"
      },
      "source": [
        "在这里，结果与我们使用PyTorch所做的结果相同。 好吧，让我们现在stack它们。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ1Ons4fPR7a",
        "outputId": "b41569bc-21f9-4080-cd88-bc475f89b6f9"
      },
      "source": [
        "tf.stack((t1,t2,t3),axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[1, 1, 1],\n",
              "       [2, 2, 2],\n",
              "       [3, 3, 3]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo0fXooWPfKy"
      },
      "source": [
        "同样，结果与PyTorch结果相同。 现在，我们将在手动插入新尺寸后将它们连接起来。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Daypr8gdPZcB",
        "outputId": "3604c9fb-08c8-4b36-8fb0-6bf428f32e7e"
      },
      "source": [
        "tf.concat(\n",
        "    (\n",
        "        tf.expand_dims(t1,0)\n",
        "        ,tf.expand_dims(t2,0)\n",
        "        ,tf.expand_dims(t3,0)\n",
        "    ),\n",
        "    axis=0\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[1, 1, 1],\n",
              "       [2, 2, 2],\n",
              "       [3, 3, 3]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taC11rQ7Px3o"
      },
      "source": [
        "与PyTorch调用相反，这个TensorFlow代码的区别在于cat（）函数现在被称为concat（）。此外，我们还使用expand_dims（）函数添加与unsqueze（）函数相对的轴。\n",
        "\n",
        "* Unsqueezing and expanding dims mean the same thing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XORrzpNrP4D5"
      },
      "source": [
        "好吧，让我们相对于第二个轴进行堆叠。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbNT2KwSPq4p",
        "outputId": "07714bf8-f514-4f47-f030-ded817b26381"
      },
      "source": [
        "tf.stack((t1,t2,t3),axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[1, 2, 3],\n",
              "       [1, 2, 3],\n",
              "       [1, 2, 3]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0OQFuaJP9WJ"
      },
      "source": [
        "并以手动轴的方式插入。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jusZgskP6wK",
        "outputId": "bad1a997-21e8-4377-971b-49ac1cde13fa"
      },
      "source": [
        "tf.concat(\n",
        "    (\n",
        "        tf.expand_dims(t1,1),\n",
        "        tf.expand_dims(t2,1),\n",
        "        tf.expand_dims(t3,1)\n",
        "    )\n",
        "    ,axis=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[1, 2, 3],\n",
              "       [1, 2, 3],\n",
              "       [1, 2, 3]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpDdWamUQZUh"
      },
      "source": [
        "观察到这些结果与PyTorch一致。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-QRq-LdQaLo"
      },
      "source": [
        "## 4.NumPy中的Stack Vs Concatenate\n",
        "现在让我们使用 NumPy。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7S6Uf7vQWwK",
        "outputId": "20baf7db-2b18-4613-f5f0-937ec9f92093"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "t1 = np.array([1,1,1])\n",
        "t2 = np.array([2,2,2])\n",
        "t3 = np.array([3,3,3])\n",
        "t1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYeFGxQbQmE4"
      },
      "source": [
        "在这里，我们创建了三个张量。 现在，让我们将它们彼此concatenate在一起。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afqlCR0BQjz6",
        "outputId": "0b713edf-4aa3-43af-b168-4dca0cc006cc"
      },
      "source": [
        "np.concatenate((t1,t2,t3),axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 2, 2, 2, 3, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8buchpwQsxZ",
        "outputId": "29a47c6c-a354-4612-a079-5bba022213f5"
      },
      "source": [
        "np.concatenate((t1,t2,t3),axis=0).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK_1ZDrdQ4Mo"
      },
      "source": [
        "好吧，这给了我们我们所期望的。 请注意，与TensorFlow一样，NumPy也使用了轴参数名称，但是在这里，我们还看到了另一个命名变体。 NumPy使用完整单词串联作为函数名称。\n",
        "\n",
        "\n",
        "|Library\t|Function Name|\n",
        "|:---:|:---:|\n",
        "|PyTorch\t|cat()|\n",
        "|TensorFlow\t|concat()|\n",
        "|NumPy\t|concatenate()|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1aE4AYpRG9Y"
      },
      "source": [
        "好吧，让我们现在stack。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvekLuf5Q0Yp",
        "outputId": "1d5d4772-0391-45c4-db6a-7b805b05ace4"
      },
      "source": [
        "np.stack((t1,t2,t3),axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1],\n",
              "       [2, 2, 2],\n",
              "       [3, 3, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VOjpj9TRSaP"
      },
      "source": [
        "如预期的那样，结果是2级张量，其形状为3 x3。现在，我们将尝试手动方式。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35O1CGV3ROOp",
        "outputId": "28779d06-d361-4be2-eaa5-70e5fce2ba44"
      },
      "source": [
        "np.concatenate(\n",
        "    (\n",
        "        np.expand_dims(t1,0),\n",
        "        np.expand_dims(t2,0),\n",
        "        np.expand_dims(t3,0)\n",
        "    ),\n",
        "    axis=0\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1],\n",
              "       [2, 2, 2],\n",
              "       [3, 3, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGQlHVSzRrhv"
      },
      "source": [
        "请注意，结果与使用stack（）函数时的结果相同。 此外，请注意，NumPy还将术语expand dims用作函数名称。\n",
        "\n",
        "现在，我们将使用第二个轴进行stack以完成此操作。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZQ0nfnGRdrZ",
        "outputId": "0dee3fef-75ad-4307-e267-3b376c822ed1"
      },
      "source": [
        "np.stack((t1,t2,t3),axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [1, 2, 3],\n",
              "       [1, 2, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBvHgIobR0iY"
      },
      "source": [
        "手动插入。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma38XgE6RxlZ",
        "outputId": "198bab3a-0b3d-4933-989b-7350a39e15f9"
      },
      "source": [
        "np.concatenate(\n",
        "    (\n",
        "        np.expand_dims(t1,1),\n",
        "        np.expand_dims(t2,1),\n",
        "        np.expand_dims(t3,1)\n",
        "    ),\n",
        "    axis=1\n",
        "\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [1, 2, 3],\n",
              "       [1, 2, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxTMrv2qSI9o"
      },
      "source": [
        "## 5.Stack或Concat：真实示例\n",
        "下面是我们在现实生活中可以遇到的三个具体例子。让我们决定什么时候需要stack，什么时候需要concatenate。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kIoC8RDST1X"
      },
      "source": [
        "### 将图像合并为一个批处理\n",
        "---\n",
        "假设我们有三个单独的图像作为张量。 每个图像张量具有三个维度，即通道轴，高度轴，宽度轴。 请注意，每个张量彼此独立。 现在，假设我们的任务是将这些张量连接在一起以形成三个图像的单批张量。\n",
        "\n",
        "* 我们是concat还是stack？\n",
        "\n",
        "好吧，请注意，在此示例中，仅存在三个维度，而对于一个批次，我们需要四个维度。 这意味着答案是沿着新轴stack张量。 该新轴将成为批处理轴。 通过为批次添加一个张量，这将为我们提供具有四个尺寸的单个张量。\n",
        "\n",
        "请注意，如果我们沿任何现有尺寸将这三个尺寸结合在一起，则会弄乱通道，高度或宽度。 我们不想这样弄乱我们的数据。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm5Kwnb4SGRZ"
      },
      "source": [
        "import torch\n",
        "t1 = torch.zeros(3,28,28)\n",
        "t2 = torch.zeros(3,28,28)\n",
        "t3 = torch.zeros(3,28,28)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WmjiddnSfso",
        "outputId": "b680ebd4-a289-49f2-dcad-d9bf0c1513a4"
      },
      "source": [
        "torch.stack(\n",
        "    (t1,t2,t3),\n",
        "    dim=0\n",
        ").shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt-Ggx0pS8YX"
      },
      "source": [
        "### 将多个批次合并为一个批次\n",
        "---\n",
        "现在，假设我们具有与以前相同的三个图像，但是这次图像已经具有该批次的尺寸。 这实际上意味着我们有三批尺寸为1的批次。 假设获得单批三个图像是我们的任务。\n",
        "\n",
        "* 我们是合并还是堆叠？\n",
        "\n",
        "好吧，请注意如何可以存在一个现有维度。 这意味着我们在批处理维度上将它们合并在一起。 在这种情况下，无需堆叠。\n",
        "\n",
        "这是一个代码示例：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aj4uy1vTFXI"
      },
      "source": [
        "import torch\n",
        "t1 = torch.zeros(1,3,28,28)\n",
        "t2 = torch.zeros(1,3,28,28)\n",
        "t3 = torch.zeros(1,3,28,28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p_u6l7kTLZI",
        "outputId": "3bce1080-d655-44e4-f3ed-d73798e17438"
      },
      "source": [
        "torch.cat(\n",
        "    (t1,t2,t3),\n",
        "    dim=0\n",
        ").shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCaFy7ntTSNh"
      },
      "source": [
        "让我们看看第三个。 这个很难。 或至少更高级。 您会明白为什么"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HRrfdYzTTdv"
      },
      "source": [
        "### 结合现有批次的图​​像\n",
        "---\n",
        "假设我们有相同的三个单独的图像张量。 只是这次，我们已经有了一个批处理张量。 假设我们的任务是将这三个单独的图像与批次结合在一起。\n",
        "\n",
        "* 我们是合并还是堆叠？\n",
        "\n",
        "好吧，请注意批处理轴中的批处理轴已经存在。 但是，对于图像，不存在批处理轴。 这意味着这些都不起作用。 要与stack或cat连接，我们需要张量具有匹配的形状。 那么，我们被卡住了吗？ 这不可能吗？\n",
        "\n",
        "确实有可能。 这实际上是非常常见的任务。 答案是先堆叠然后再连接。\n",
        "\n",
        "我们首先堆叠相对于第一维的三个图像张量。 这将创建一个长度为3的新批次尺寸。 然后，我们可以用批处理张量连接这个新的张量。\n",
        "\n",
        "让我们在代码中看一个例子：\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2O_f0pgTPb4"
      },
      "source": [
        "import torch\n",
        "batch = torch.zeros(3,3,28,28)\n",
        "t1 = torch.zeros(3,28,28)\n",
        "t2 = torch.zeros(3,28,28)\n",
        "t3 = torch.zeros(3,28,28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbt6q00YTgTo",
        "outputId": "49b2798c-3e20-40db-b41b-cc374c2d8ce1"
      },
      "source": [
        "torch.cat(\n",
        "    (\n",
        "        batch,\n",
        "        torch.stack(\n",
        "            (t1,t2,t3),\n",
        "            dim=0\n",
        "        )\n",
        "    ),\n",
        "    dim=0\n",
        ").shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 3, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5Zl5sAoTx2H"
      },
      "source": [
        "同样地："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI9H8nv_TrxI"
      },
      "source": [
        "import torch\n",
        "batch = torch.zeros(3,3,28,28)\n",
        "t1 = torch.zeros(3,28,28)\n",
        "t2 = torch.zeros(3,28,28)\n",
        "t3 = torch.zeros(3,28,28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXrMIEz3TzKo",
        "outputId": "fb43a0cd-ca08-4cd0-c01c-78a8ec9659b6"
      },
      "source": [
        "torch.cat(\n",
        "    (\n",
        "        batch,\n",
        "        t1.unsqueeze(0),\n",
        "        t2.unsqueeze(0),\n",
        "        t3.unsqueeze(0)\n",
        "    ),\n",
        "    dim=0\n",
        ").shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 3, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpOU-AjGUEDn"
      },
      "source": [
        "我希望这会有所帮助，并且您现在就掌握了。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVuFZBooT_Mn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}