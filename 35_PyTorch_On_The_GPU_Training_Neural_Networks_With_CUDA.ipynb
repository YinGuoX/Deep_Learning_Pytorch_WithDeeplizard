{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "35_PyTorch On The GPU - Training Neural Networks With CUDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPrP91V1LRBWyt0H45l9MGO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3bb0b34cb44d45dabaf1065f41bc152a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_79c8c434658f4115b93743c8d7602dfb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b265bb75410a471faa48ae919a067e31",
              "IPY_MODEL_39720807737e4397a8cf32fdfca77d2d"
            ]
          }
        },
        "79c8c434658f4115b93743c8d7602dfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b265bb75410a471faa48ae919a067e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2efee77c1bca4808b83e5650e846a09a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 26421880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 26421880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61572d0f62fc4d26b142a5266205aae0"
          }
        },
        "39720807737e4397a8cf32fdfca77d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df2b551fe86f4b75b80801406b9afab6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26422272/? [00:48&lt;00:00, 539423.74it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c790cf6e84be4622bfec7a1d2370cc71"
          }
        },
        "2efee77c1bca4808b83e5650e846a09a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61572d0f62fc4d26b142a5266205aae0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df2b551fe86f4b75b80801406b9afab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c790cf6e84be4622bfec7a1d2370cc71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7eae7c5d4b9b4a669ffbd7a6719fa6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2ff63ca2aab14fa59e87286c7294afb2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_19aeff08dff34581b8673dcd429cea69",
              "IPY_MODEL_0e716fac1616493fac18c7f184b6e2e4"
            ]
          }
        },
        "2ff63ca2aab14fa59e87286c7294afb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19aeff08dff34581b8673dcd429cea69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_820e72332c4e4ff8bf8fa6137a489726",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29515,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29515,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa2a62c1bb9d4cfbb99fb589d63b389d"
          }
        },
        "0e716fac1616493fac18c7f184b6e2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ae6317eaab854b71ae229455ed89e30b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:00&lt;00:00, 59041.41it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b744005a2a64b6a8c7ac3ee9db3872c"
          }
        },
        "820e72332c4e4ff8bf8fa6137a489726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa2a62c1bb9d4cfbb99fb589d63b389d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae6317eaab854b71ae229455ed89e30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b744005a2a64b6a8c7ac3ee9db3872c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "635c4da17f0549ac97ec561c4485ca7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c5f72f25da22414fa3dcebbd0c487c89",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_537a9352ccdf4229b8de74598df6a19a",
              "IPY_MODEL_102afd4aec8648b1aa3b4730e5540a76"
            ]
          }
        },
        "c5f72f25da22414fa3dcebbd0c487c89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "537a9352ccdf4229b8de74598df6a19a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7483c61616a641ec8b1f5a5ea4fee762",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4422102,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4422102,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_196d88d2ae334eaaac5ce1e316c936e5"
          }
        },
        "102afd4aec8648b1aa3b4730e5540a76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7d1e584e6f8c453981b6a5d77b48a9cf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4422656/? [00:46&lt;00:00, 95695.59it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b4b0f9934f54d19a2d6940773cd97eb"
          }
        },
        "7483c61616a641ec8b1f5a5ea4fee762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "196d88d2ae334eaaac5ce1e316c936e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d1e584e6f8c453981b6a5d77b48a9cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b4b0f9934f54d19a2d6940773cd97eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bcd8b37df484e16afbc29d8b2824eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_942811655d4c4616a06253f7c10d0f5c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fe262d8827224899a437953aaf81a496",
              "IPY_MODEL_d196ded69220427ea22df46a9fd48e48"
            ]
          }
        },
        "942811655d4c4616a06253f7c10d0f5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe262d8827224899a437953aaf81a496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_10b1346d2b2f4c60bb63c39903044e43",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5148,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5148,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_06db5c43cbf94bd294c2c2e6c8374c65"
          }
        },
        "d196ded69220427ea22df46a9fd48e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dcc94a6c4e044ca48bdf6eba73099a99",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6144/? [00:40&lt;00:00, 152.57it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d12f1eba0e44d50a07d791a3d7c4bb2"
          }
        },
        "10b1346d2b2f4c60bb63c39903044e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "06db5c43cbf94bd294c2c2e6c8374c65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dcc94a6c4e044ca48bdf6eba73099a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d12f1eba0e44d50a07d791a3d7c4bb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YinGuoX/Deep_Learning_Pytorch_WithDeeplizard/blob/master/35_PyTorch_On_The_GPU_Training_Neural_Networks_With_CUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwRFS9VCr8UA"
      },
      "source": [
        "# Run PyTorch Code On A GPU - Neural Network Programming Guide\n",
        "\n",
        "在本节中，我们将学习如何在PyTorch中使用GPU。 我们将看到一般如何使用GPU，还将看到如何将这些常规技术应用于训练我们的神经网络。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdNSP8e8sHVu"
      },
      "source": [
        "## 1.使用GPU进行深度学习\n",
        "\n",
        "现在，我们将以PyTorch GPU示例为基础\n",
        "\n",
        "### PyTorch GPU示例\n",
        "--- \n",
        "在我们在程序内部执行计算时，PyTorch允许我们无缝地在GPU之间来回移动数据。\n",
        "\n",
        "当我们使用GPU时，可以使用cuda（）方法，当我们使用CPU时，可以使用cpu（）方法。\n",
        "\n",
        "我们也可以使用to（）方法。 要转到GPU，我们要写入to（'cuda'），要转到CPU，我们要写入to（'cpu'）。 to（）方法是首选方法，主要是因为它更灵活。 我们将看到使用前两个示例的示例，然后默认使用始终使用to（）变体的示例。\n",
        "\n",
        "|CPU|GPU|\n",
        "|:---:|:---:|\n",
        "|cpu()|cuda()|\n",
        "|to('cpu')|to('cuda')|\n",
        "\n",
        "要在培训过程中使用我们的GPU，有两个基本要求。 这些要求如下:\n",
        "* 数据必须移至GPU\n",
        "* 网络必须移至GPU。\n",
        "\n",
        "默认情况下，创建PyTorch张量或PyTorch神经网络模块时，将在CPU上初始化相应的数据。 具体来说，数据存在于CPU的内存中。\n",
        "\n",
        "现在，让我们创建一个张量和一个网络，并看看我们如何进行从CPU到GPU的迁移。\n",
        "\n",
        "在这里，我们创建一个张量和一个网络：\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhoVS82AtAeO"
      },
      "source": [
        "# 实际的源码\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbtV59OSs_22"
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6,out_channels=12,kernel_size=5)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=12*4*4,out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120,out_features=60)\n",
        "    self.out = nn.Linear(in_features=60,out_features=10)\n",
        "\n",
        "  \n",
        "  def forward(self,t):\n",
        "    t= t\n",
        "\n",
        "    t = self.conv1(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t,kernel_size=2,stride=2)\n",
        "\n",
        "    t = self.conv2(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t,kernel_size=2,stride=2)\n",
        "\n",
        "    t = t.reshape(-1,12*4*4)\n",
        "    t = self.fc1(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    t = self.fc2(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    t = self.out(t)\n",
        "\n",
        "    return t;\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT23YRPjs_sX"
      },
      "source": [
        "t = torch.ones(1,1,28,28)\n",
        "network = Network()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6-MkPcps_TX"
      },
      "source": [
        "现在，我们调用cuda（）方法，并将张量和网络重新分配给已复制到GPU上的返回值："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzgoZHnarrEL"
      },
      "source": [
        "t =t.cuda()\n",
        "network = network.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIECG5JxtVOu"
      },
      "source": [
        "接下来，我们可以从网络获得预测，并看到预测张量的device属性确认数据在cuda（即GPU）上："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlTJA1qRtRV3",
        "outputId": "fef82a36-d399-459f-afd5-3619096924e3"
      },
      "source": [
        "gpu_pred = network(t)\n",
        "gpu_pred.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqshRIestdr-"
      },
      "source": [
        "同样，我们可以采取相反的方式："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFxt1Ny1ta-X",
        "outputId": "b6020163-ce13-43fe-db54-be60693cb42d"
      },
      "source": [
        "t = t.cpu()\n",
        "network = network.cpu()\n",
        "\n",
        "cpu_pred = network(t)\n",
        "cpu_pred.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYglxA4vtr3G"
      },
      "source": [
        "简而言之，这就是我们如何利用PyTorch的GPU功能。 现在，我们要讨论的是一些重要的细节，这些细节潜伏在我们刚刚看到的代码的表面之下。\n",
        "\n",
        "例如，尽管我们使用了cuda（）和cpu（）方法，但实际上它们并不是我们的最佳选择。 此外，网络实例和张量实例之间的方法有什么区别？ 这些毕竟是不同的对象类型，这意味着这两种方法是不同的。 最后，我们希望将此代码集成到一个有效的示例中并进行性能测试。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2EMDaiNttVW"
      },
      "source": [
        "### 使用GPU的总体思路\n",
        "---\n",
        "\n",
        "此时的主要结论是，我们的网络和数据都必须同时存在于GPU上，才能使用GPU进行计算，这适用于任何编程语言或框架。\n",
        "\n",
        "我们将在下一个演示中看到，CPU也是如此。gpu和cpu是对数据进行计算的计算设备，因此在计算中直接相互使用的任何两个值必须存在于同一设备上。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsxsTJQNt6x_"
      },
      "source": [
        "## 2.基于GPU的PyTorch张量计算\n",
        "让我们通过演示一些张量计算来更深入地研究。\n",
        "\n",
        "我们将从创建两个张量开始："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1kA4rB9tmUG"
      },
      "source": [
        "t1 = torch.tensor([\n",
        "    [1,2],\n",
        "    [3,4]\n",
        "])\n",
        "\n",
        "t2 = torch.tensor([\n",
        "    [5,6],\n",
        "    [7,8]\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxre1X5fuCGe"
      },
      "source": [
        "现在，我们将通过检查device属性来检查这些张量在哪个设备上初始化："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oey9p-Sct_a3",
        "outputId": "8453820d-67dd-4ce5-b36d-af4314ed57c2"
      },
      "source": [
        "t.device,t2.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cpu'), device(type='cpu'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w3ut3S7uIgO"
      },
      "source": [
        "正如我们所期望的，我们看到，实际上，两个张量都在同一设备上，即CPU。 让我们将第一个张量t1移至GPU。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7bAurNtuFdn",
        "outputId": "ebf10454-5421-446c-8137-7bd9424f33d5"
      },
      "source": [
        "t1 = t1.to('cuda')\n",
        "t1.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaWbJ1F6uTWG"
      },
      "source": [
        "我们可以看到，这个张量的设备已经改成了cuda，GPU。注意这里to（）方法的用法。我们不调用特定的方法来移动到设备，而是调用相同的方法并传递指定设备的参数。使用to（）方法是在设备之间移动数据的首选方法。\n",
        "\n",
        "另外，请注意重新分配。操作不到位，因此需要重新分配。\n",
        "\n",
        "让我们做个实验。我想通过对这两个张量t1和t2进行计算来测试我们之前讨论的内容，我们现在知道这两个张量在不同的设备上。\n",
        "\n",
        "因为我们预期会出现错误，所以我们将调用包装为try并捕获异常："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUp3OAepuLjX",
        "outputId": "8ec8fdff-fc0f-4918-a709-bd6e5d428e3f"
      },
      "source": [
        "try:\n",
        "  t1+t2\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsJRiIcDueNu"
      },
      "source": [
        "通过颠倒操作顺序，我们可以看到错误也发生了变化："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRP3bpq0uaV1",
        "outputId": "d085df44-61b7-4b48-d874-c162047184af"
      },
      "source": [
        "try:\n",
        "  t2+t1\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc1wf3wjuknO"
      },
      "source": [
        "这两个错误都告诉我们，二进制加号运算符期望第二个参数与第一个参数具有相同的设备。 调试这些类型的设备不匹配时，了解此错误的含义可能会有所帮助。\n",
        "\n",
        "最后，为了完成操作，让我们将第二张量移动到cuda设备以查看操作是否成功。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX2LxX6hugBm",
        "outputId": "40257e1a-5dc6-415a-bcf2-966b7c180590"
      },
      "source": [
        "t2 = t2.to('cuda')\n",
        "t1+t2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6,  8],\n",
              "        [10, 12]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zptrv69uuqO"
      },
      "source": [
        "## 3.基于GPU的Pytorch nn.Module的计算\n",
        "\n",
        "我们已经看到了如何在设备之间来回移动张量。 现在，让我们看看如何使用PyTorch nn.Module实例完成此操作。\n",
        "\n",
        "更笼统地说，我们有兴趣了解网络在诸如GPU或CPU的设备上的含义以及含义。 撇开PyTorch，这是必不可少的问题。\n",
        "\n",
        "通过将网络参数移至该设备，将网络放置在该设备上。 让我们创建一个网络，看看我们的意思。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfsMHfL6unfn"
      },
      "source": [
        "network = Network()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7TOs_j1u71u"
      },
      "source": [
        "现在，让我们看一下网络的参数："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOD8fjtau5h4",
        "outputId": "f7b7ba2c-fe23-4701-9fee-ad3db431d504"
      },
      "source": [
        "for name,param in network.named_parameters():\n",
        "  print(name,'\\t\\t',param.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.weight \t\t torch.Size([6, 1, 5, 5])\n",
            "conv1.bias \t\t torch.Size([6])\n",
            "conv2.weight \t\t torch.Size([12, 6, 5, 5])\n",
            "conv2.bias \t\t torch.Size([12])\n",
            "fc1.weight \t\t torch.Size([120, 192])\n",
            "fc1.bias \t\t torch.Size([120])\n",
            "fc2.weight \t\t torch.Size([60, 120])\n",
            "fc2.bias \t\t torch.Size([60])\n",
            "out.weight \t\t torch.Size([10, 60])\n",
            "out.bias \t\t torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFRqOixmvIbe"
      },
      "source": [
        "在这里，我们创建了一个PyTorch网络，并迭代了该网络的参数。 如我们所见，网络的参数是网络内部的权重和偏差。\n",
        "\n",
        "换句话说，这些只是存在于我们已经看到的设备上的张量。 让我们通过检查每个参数的设备来验证这一点。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XtSovcrvDyH",
        "outputId": "5b5b68d3-f665-40fd-ebde-14aaf145357d"
      },
      "source": [
        "for n ,p in network.named_parameters():\n",
        "  print(p.device,'',n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu  conv1.weight\n",
            "cpu  conv1.bias\n",
            "cpu  conv2.weight\n",
            "cpu  conv2.bias\n",
            "cpu  fc1.weight\n",
            "cpu  fc1.bias\n",
            "cpu  fc2.weight\n",
            "cpu  fc2.bias\n",
            "cpu  out.weight\n",
            "cpu  out.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfYBGWs2vZk9"
      },
      "source": [
        "这表明，默认情况下，网络内部的所有参数都是在CPU上初始化的。\n",
        "\n",
        "一个重要的考虑因素是它解释了为什么像网络这样的nn.Module实例实际上没有设备。 设备上的网络不是网络，而是设备上的网络内部的张量。\n",
        "\n",
        "让我们看看当我们要求将网络移动到GPU时会发生什么："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKmzcJmrvQz3",
        "outputId": "6431b9d3-3259-42ff-d80a-598795ee45e9"
      },
      "source": [
        "network.to('cuda')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
              "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AzzmTmgvi9-"
      },
      "source": [
        "请注意，此处不需要重新分配实例来接收。 这是因为就网络实例而言，该操作是就地的。 所以，该操作可以用作重新分配操作。 对于nn.Module实例和PyTorch张量之间的一致性，首选此方法。\n",
        "\n",
        "在这里，我们可以看到，现在所有网络参数都有一个cuda设备："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XfUipK4vcaX",
        "outputId": "b6d15bed-0bc1-44b0-a524-66200f62f520"
      },
      "source": [
        "for n ,p in network.named_parameters():\n",
        "  print(p.device,'',n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0  conv1.weight\n",
            "cuda:0  conv1.bias\n",
            "cuda:0  conv2.weight\n",
            "cuda:0  conv2.bias\n",
            "cuda:0  fc1.weight\n",
            "cuda:0  fc1.bias\n",
            "cuda:0  fc2.weight\n",
            "cuda:0  fc2.bias\n",
            "cuda:0  out.weight\n",
            "cuda:0  out.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDhBM_vPvu-1"
      },
      "source": [
        "### 将样本传递到网络\n",
        "---\n",
        "让我们通过将示例传递到网络来结束本演示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GtjcHbBvrSH",
        "outputId": "54a6da50-2122-485e-84e7-86576ba49565"
      },
      "source": [
        "sample = torch.ones(1,1,28,28)\n",
        "sample.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi4WcQuHvxpG",
        "outputId": "486127f1-bf50-4e08-e1b4-c0f0d9619369"
      },
      "source": [
        "try:\n",
        "    network(sample)\n",
        "except Exception as e: \n",
        "    print(e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5t8SvYpv4G1"
      },
      "source": [
        "由于我们的网络位于GPU上，并且默认情况下此新创建的示例位于CPU上，因此我们会收到错误消息。 该错误告诉我们，在调用第一卷积层的forward方法时，CPU张量应为GPU张量。 这正是我们之前直接添加两个张量时所看到的。\n",
        "\n",
        "我们可以通过将示例发送到GPU来解决此问题，如下所示：\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukDn5x_8vzN2",
        "outputId": "07d95ba4-0de9-4837-b078-5f543da03f20"
      },
      "source": [
        "try:\n",
        "    pred = network(sample.to('cuda'))\n",
        "    print(pred)\n",
        "except Exception as e:\n",
        "    print(e)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.1230,  0.1012, -0.0821, -0.1597,  0.1082, -0.0302,  0.0479,  0.0897,\n",
            "          0.0565,  0.0540]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwAO0R_4v_6d"
      },
      "source": [
        "最后，一切都按预期进行，我们得到了一个预测。\n",
        "\n",
        "### 编写与设备无关的PyTorch代码\n",
        "---\n",
        "在总结之前，我们需要讨论编写与设备无关的代码。 这个与设备无关的术语意味着我们的代码不依赖于底层设备。 阅读PyTorch文档时，您可能会遇到此术语。\n",
        "\n",
        "例如，假设我们编写的代码到处都使用cuda（）方法，然后将代码提供给没有GPU的用户。 这行不通。 不用担心 我们有选择！\n",
        "\n",
        "还记得我们之前看到的cuda（）和cpu（）方法吗？\n",
        "\n",
        "我们之所以首选to（）方法的原因之一是，因为to（）方法是参数化的，这使得更改我们选择的设备变得更加容易，即它很灵活！\n",
        "\n",
        "例如，用户可以将cpu或cuda作为参数传递给深度学习程序，这将使该程序与设备无关。\n",
        "\n",
        "允许程序用户传递确定程序行为的参数，这可能是使程序与设备无关的最佳方法。 但是，我们也可以使用PyTorch来检查受支持的GPU，并以此方式设置设备。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2-aqdgbwPTV",
        "outputId": "5984e959-0a4e-4ec6-ff96-1af6d896a2ab"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7LMSULnwT_e"
      },
      "source": [
        "就像，如果cuda可用，请使用它！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCy5PKsCwNq1"
      },
      "source": [
        "## 4.PyTorch GPU训练性能测试\n",
        "\n",
        "现在让我们看看如何将GPU的使用添加到训练循环中。 我们将使用本系列到目前为止开发的代码进行此添加。\n",
        "\n",
        "这将使我们能够轻松比较CPU和GPU的时间。\n",
        "\n",
        "### 重构RunManager类\n",
        "---\n",
        "\n",
        "在更新训练循环之前，我们需要更新RunManager类。 在begin_run（）方法内部，我们需要修改传递给add_graph方法的图像张量的设备。\n",
        "\n",
        "它看起来应该像这样：\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def begin_run(self, run, network, loader):\n",
        "\n",
        "    self.run_start_time = time.time()\n",
        "\n",
        "    self.run_params = run\n",
        "    self.run_count += 1\n",
        "\n",
        "    self.network = network\n",
        "    self.loader = loader\n",
        "    self.tb = SummaryWriter(comment=f'-{run}')\n",
        "\n",
        "    images, labels = next(iter(self.loader))\n",
        "    grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "    self.tb.add_image('images', grid)\n",
        "    self.tb.add_graph(\n",
        "            self.network\n",
        "        ,images.to(getattr(run, 'device', 'cpu'))\n",
        "    )\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cDQGLWnwwuG"
      },
      "source": [
        "在这里，我们使用内置的getattr（）函数来获取运行对象上设备的值。 如果运行对象没有设备，则返回cpu。 这使代码向后兼容。 如果我们没有为运行指定设备，它将仍然有效。\n",
        "\n",
        "请注意，网络不需要移动到设备，因为它是在传入设备之前设置的。但是，图像张量是从加载程序获得的。\n",
        "\n",
        "\n",
        "### 重构训练循环\n",
        "---\n",
        "我们将配置参数设置为具有设备。 这里的两个逻辑选项是cuda和cpu。\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "params = OrderedDict(\n",
        "    lr = [.01]\n",
        "    ,batch_size = [1000, 10000, 20000]\n",
        "    , num_workers = [0, 1]\n",
        "    , device = ['cuda', 'cpu']\n",
        ")\n",
        "```\n",
        "将这些设备值添加到我们的配置中后，现在就可以在我们的训练循环中对其进行访问。\n",
        "\n",
        "在run的顶部，我们将创建一个将在run内和训练循环内传递的设备。\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "device = torch.device(run.device)\n",
        "```\n",
        "\n",
        "我们将首先使用此设备的是在初始化网络时。\n",
        "\n",
        "\n",
        "```\n",
        "network = Network().to(device)\n",
        "```\n",
        "\n",
        "这将确保将网络移动到适当的设备。 最后，我们将通过分别解压缩图像和标签张量并将其发送到设备来更新图像和标签张量：\n",
        "\n",
        "\n",
        "```\n",
        "network = Network().to(device)\n",
        "```\n",
        "images = batch[0].to(device)\n",
        "labels = batch[1].to(device)\n",
        "\n",
        "这就是全部，我们已经准备好运行此代码并查看结果。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7majZk-v9GW"
      },
      "source": [
        "# 完整代码\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2ze2L4Qxfod"
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6,out_channels=12,kernel_size=5)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=12*4*4,out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120,out_features=60)\n",
        "    self.out = nn.Linear(in_features=60,out_features=10)\n",
        "\n",
        "  \n",
        "  def forward(self,t):\n",
        "    t= t\n",
        "\n",
        "    t = self.conv1(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t,kernel_size=2,stride=2)\n",
        "\n",
        "    t = self.conv2(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t,kernel_size=2,stride=2)\n",
        "\n",
        "    t = t.reshape(-1,12*4*4)\n",
        "    t = self.fc1(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    t = self.fc2(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    t = self.out(t)\n",
        "\n",
        "    return t;\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579,
          "referenced_widgets": [
            "3bb0b34cb44d45dabaf1065f41bc152a",
            "79c8c434658f4115b93743c8d7602dfb",
            "b265bb75410a471faa48ae919a067e31",
            "39720807737e4397a8cf32fdfca77d2d",
            "2efee77c1bca4808b83e5650e846a09a",
            "61572d0f62fc4d26b142a5266205aae0",
            "df2b551fe86f4b75b80801406b9afab6",
            "c790cf6e84be4622bfec7a1d2370cc71",
            "7eae7c5d4b9b4a669ffbd7a6719fa6e2",
            "2ff63ca2aab14fa59e87286c7294afb2",
            "19aeff08dff34581b8673dcd429cea69",
            "0e716fac1616493fac18c7f184b6e2e4",
            "820e72332c4e4ff8bf8fa6137a489726",
            "fa2a62c1bb9d4cfbb99fb589d63b389d",
            "ae6317eaab854b71ae229455ed89e30b",
            "6b744005a2a64b6a8c7ac3ee9db3872c",
            "635c4da17f0549ac97ec561c4485ca7f",
            "c5f72f25da22414fa3dcebbd0c487c89",
            "537a9352ccdf4229b8de74598df6a19a",
            "102afd4aec8648b1aa3b4730e5540a76",
            "7483c61616a641ec8b1f5a5ea4fee762",
            "196d88d2ae334eaaac5ce1e316c936e5",
            "7d1e584e6f8c453981b6a5d77b48a9cf",
            "9b4b0f9934f54d19a2d6940773cd97eb",
            "5bcd8b37df484e16afbc29d8b2824eeb",
            "942811655d4c4616a06253f7c10d0f5c",
            "fe262d8827224899a437953aaf81a496",
            "d196ded69220427ea22df46a9fd48e48",
            "10b1346d2b2f4c60bb63c39903044e43",
            "06db5c43cbf94bd294c2c2e6c8374c65",
            "dcc94a6c4e044ca48bdf6eba73099a99",
            "3d12f1eba0e44d50a07d791a3d7c4bb2"
          ]
        },
        "id": "cFJAPCG2xf_V",
        "outputId": "ec72ee60-bb54-4fb0-9e94-c400a89e259e"
      },
      "source": [
        "train_set = torchvision.datasets.FashionMNIST(root='./data',train=True,\n",
        "                                download=True,\n",
        "                                transform=transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bb0b34cb44d45dabaf1065f41bc152a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=26421880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7eae7c5d4b9b4a669ffbd7a6719fa6e2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=29515.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "635c4da17f0549ac97ec561c4485ca7f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4422102.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bcd8b37df484e16afbc29d8b2824eeb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5148.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99bSEl_bxhBH"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from IPython.display import display, clear_output\n",
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "\n",
        "from itertools import product\n",
        "from collections import namedtuple\n",
        "from collections import OrderedDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YboccJxwxizm"
      },
      "source": [
        "class RunBuilder():\n",
        "    @staticmethod\n",
        "    def get_runs(params):\n",
        "\n",
        "        Run = namedtuple('Run', params.keys())\n",
        "\n",
        "        runs = []\n",
        "        for v in product(*params.values()):\n",
        "          runs.append(Run(*v))\n",
        "        return runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpNPyNfMxmC3"
      },
      "source": [
        "params = OrderedDict(\n",
        "    lr = [0.01,0.001,0.0001],\n",
        "    batch_size = [100,1000,10000,20000],\n",
        "    num_workers=[0,1,2,4],\n",
        "    device = ['cuda','cpu']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVigtjjaxugn",
        "outputId": "5345f3f8-5c68-4046-c4f0-c64fab53d414"
      },
      "source": [
        "for run in RunBuilder.get_runs(params):\n",
        "  print(run.lr,run.batch_size,run.num_workers,run.device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.01 100 0 cuda\n",
            "0.01 100 0 cpu\n",
            "0.01 100 1 cuda\n",
            "0.01 100 1 cpu\n",
            "0.01 100 2 cuda\n",
            "0.01 100 2 cpu\n",
            "0.01 100 4 cuda\n",
            "0.01 100 4 cpu\n",
            "0.01 1000 0 cuda\n",
            "0.01 1000 0 cpu\n",
            "0.01 1000 1 cuda\n",
            "0.01 1000 1 cpu\n",
            "0.01 1000 2 cuda\n",
            "0.01 1000 2 cpu\n",
            "0.01 1000 4 cuda\n",
            "0.01 1000 4 cpu\n",
            "0.01 10000 0 cuda\n",
            "0.01 10000 0 cpu\n",
            "0.01 10000 1 cuda\n",
            "0.01 10000 1 cpu\n",
            "0.01 10000 2 cuda\n",
            "0.01 10000 2 cpu\n",
            "0.01 10000 4 cuda\n",
            "0.01 10000 4 cpu\n",
            "0.01 20000 0 cuda\n",
            "0.01 20000 0 cpu\n",
            "0.01 20000 1 cuda\n",
            "0.01 20000 1 cpu\n",
            "0.01 20000 2 cuda\n",
            "0.01 20000 2 cpu\n",
            "0.01 20000 4 cuda\n",
            "0.01 20000 4 cpu\n",
            "0.001 100 0 cuda\n",
            "0.001 100 0 cpu\n",
            "0.001 100 1 cuda\n",
            "0.001 100 1 cpu\n",
            "0.001 100 2 cuda\n",
            "0.001 100 2 cpu\n",
            "0.001 100 4 cuda\n",
            "0.001 100 4 cpu\n",
            "0.001 1000 0 cuda\n",
            "0.001 1000 0 cpu\n",
            "0.001 1000 1 cuda\n",
            "0.001 1000 1 cpu\n",
            "0.001 1000 2 cuda\n",
            "0.001 1000 2 cpu\n",
            "0.001 1000 4 cuda\n",
            "0.001 1000 4 cpu\n",
            "0.001 10000 0 cuda\n",
            "0.001 10000 0 cpu\n",
            "0.001 10000 1 cuda\n",
            "0.001 10000 1 cpu\n",
            "0.001 10000 2 cuda\n",
            "0.001 10000 2 cpu\n",
            "0.001 10000 4 cuda\n",
            "0.001 10000 4 cpu\n",
            "0.001 20000 0 cuda\n",
            "0.001 20000 0 cpu\n",
            "0.001 20000 1 cuda\n",
            "0.001 20000 1 cpu\n",
            "0.001 20000 2 cuda\n",
            "0.001 20000 2 cpu\n",
            "0.001 20000 4 cuda\n",
            "0.001 20000 4 cpu\n",
            "0.0001 100 0 cuda\n",
            "0.0001 100 0 cpu\n",
            "0.0001 100 1 cuda\n",
            "0.0001 100 1 cpu\n",
            "0.0001 100 2 cuda\n",
            "0.0001 100 2 cpu\n",
            "0.0001 100 4 cuda\n",
            "0.0001 100 4 cpu\n",
            "0.0001 1000 0 cuda\n",
            "0.0001 1000 0 cpu\n",
            "0.0001 1000 1 cuda\n",
            "0.0001 1000 1 cpu\n",
            "0.0001 1000 2 cuda\n",
            "0.0001 1000 2 cpu\n",
            "0.0001 1000 4 cuda\n",
            "0.0001 1000 4 cpu\n",
            "0.0001 10000 0 cuda\n",
            "0.0001 10000 0 cpu\n",
            "0.0001 10000 1 cuda\n",
            "0.0001 10000 1 cpu\n",
            "0.0001 10000 2 cuda\n",
            "0.0001 10000 2 cpu\n",
            "0.0001 10000 4 cuda\n",
            "0.0001 10000 4 cpu\n",
            "0.0001 20000 0 cuda\n",
            "0.0001 20000 0 cpu\n",
            "0.0001 20000 1 cuda\n",
            "0.0001 20000 1 cpu\n",
            "0.0001 20000 2 cuda\n",
            "0.0001 20000 2 cpu\n",
            "0.0001 20000 4 cuda\n",
            "0.0001 20000 4 cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sIRWN5YxzHm"
      },
      "source": [
        "# 理解上述思想，构建RunManager()类\n",
        "class RunManager():\n",
        "  def __init__(self):\n",
        "    self.epoch_count = 0\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_num_correct = 0\n",
        "    self.epoch_start_time = None\n",
        "    self.epoch_num_workers=0\n",
        "\n",
        "\n",
        "    self.run_params = None\n",
        "    self.run_count = 0\n",
        "    self.run_data = []\n",
        "    self.run_start_time = None\n",
        "\n",
        "    self.network = None\n",
        "    self.loader = None\n",
        "    self.tb = None\n",
        "\n",
        "  \n",
        "  def begin_run(self,run,network,loader):\n",
        "    self.run_start_time = time.time()\n",
        "\n",
        "    self.run_params = run\n",
        "    self.run_count += 1\n",
        "\n",
        "    self.network = network\n",
        "    self.loader = loader\n",
        "    self.tb = SummaryWriter(comment=f'-{run}')\n",
        "\n",
        "    images, labels = next(iter(self.loader))\n",
        "    grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "    self.tb.add_image('images', grid)\n",
        "    self.tb.add_graph(\n",
        "            self.network\n",
        "        ,images.to(getattr(run, 'device', 'cpu'))\n",
        "    )\n",
        "\n",
        "  def end_run(self):\n",
        "    self.tb.close()\n",
        "    self.epoch_count = 0\n",
        "\n",
        "  def begin_epoch(self):\n",
        "    self.epoch_start_time = time.time()\n",
        "    self.epoch_count += 1\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_num_correct = 0\n",
        "\n",
        "\n",
        "  def end_epoch(self):\n",
        "\n",
        "    epoch_duration = time.time() - self.epoch_start_time\n",
        "    run_duration = time.time() - self.run_start_time\n",
        "\n",
        "    loss = self.epoch_loss / len(self.loader.dataset)\n",
        "    accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
        "\n",
        "    self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
        "    self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
        "\n",
        "    for name, param in self.network.named_parameters():\n",
        "        self.tb.add_histogram(name, param, self.epoch_count)\n",
        "        self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
        "\n",
        "    results = OrderedDict()\n",
        "    results[\"run\"] = self.run_count\n",
        "    results[\"epoch\"] = self.epoch_count\n",
        "    results['loss'] = loss\n",
        "    results[\"accuracy\"] = accuracy\n",
        "    results['epoch duration'] = epoch_duration\n",
        "    results['run duration'] = run_duration\n",
        "    results['num_workers'] = self.epoch_num_workers\n",
        "    results['device']=self.run_params.device\n",
        "    for k,v in self.run_params._asdict().items(): results[k] = v\n",
        "    self.run_data.append(results)\n",
        "\n",
        "    df = pd.DataFrame.from_dict(self.run_data, orient='columns')\n",
        "    \n",
        "    clear_output(wait=True)\n",
        "    \n",
        "    display(df)\n",
        "\n",
        "  def get_num_workers(self,num_workers):\n",
        "    self.epoch_num_workers = num_workers\n",
        "\n",
        "\n",
        "  def track_loss(self, loss, batch):\n",
        "    self.epoch_loss += loss.item() * batch[0].shape[0]\n",
        "\n",
        "  def track_num_correct(self, preds, labels):\n",
        "    self.epoch_num_correct += self.get_num_correct(preds, labels)\n",
        "\n",
        "  def get_num_correct(self, preds, labels):\n",
        "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
        "\n",
        "  def save(self, fileName):\n",
        "\n",
        "    pd.DataFrame.from_dict(\n",
        "        self.run_data, orient='columns'\n",
        "    ).to_csv(f'{fileName}.csv')\n",
        "\n",
        "    with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844
        },
        "id": "A60mFpb8yGcn",
        "outputId": "b6368dd9-568d-450d-d6b7-1a8b27375ea6"
      },
      "source": [
        "runManger = RunManager()\n",
        "for run in RunBuilder.get_runs(params):\n",
        "  print(run)\n",
        "  network = Network()\n",
        "  network.to(run.device)\n",
        "  train_loader = DataLoader(\n",
        "      train_set,\n",
        "      batch_size =run.batch_size,\n",
        "      num_workers=run.num_workers\n",
        "  )\n",
        "  optimizer = optim.Adam(network.parameters(),lr=run.lr)\n",
        "  runManger.begin_run(run,network,train_loader)\n",
        "  for epoch in range(1):\n",
        "    runManger.begin_epoch()\n",
        "    runManger.get_num_workers(run.num_workers)\n",
        "    \n",
        "    for batch in train_loader:\n",
        "      images,labels = batch\n",
        "      images = images.to(run.device)\n",
        "      labels = labels.to(run.device)      \n",
        "      preds = network(images)\n",
        "\n",
        "      loss = F.cross_entropy(preds,labels)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      runManger.track_loss(loss,batch)\n",
        "      runManger.track_num_correct(preds,labels)\n",
        "    runManger.end_epoch()\n",
        "  runManger.end_run()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run</th>\n",
              "      <th>epoch</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>epoch duration</th>\n",
              "      <th>run duration</th>\n",
              "      <th>num_workers</th>\n",
              "      <th>device</th>\n",
              "      <th>lr</th>\n",
              "      <th>batch_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.559973</td>\n",
              "      <td>0.788717</td>\n",
              "      <td>5.143286</td>\n",
              "      <td>5.242760</td>\n",
              "      <td>0</td>\n",
              "      <td>cuda</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.572739</td>\n",
              "      <td>0.783117</td>\n",
              "      <td>19.920521</td>\n",
              "      <td>20.072048</td>\n",
              "      <td>0</td>\n",
              "      <td>cpu</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.567751</td>\n",
              "      <td>0.785667</td>\n",
              "      <td>6.399574</td>\n",
              "      <td>6.592551</td>\n",
              "      <td>1</td>\n",
              "      <td>cuda</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.563203</td>\n",
              "      <td>0.785683</td>\n",
              "      <td>19.446070</td>\n",
              "      <td>19.677835</td>\n",
              "      <td>1</td>\n",
              "      <td>cpu</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.599108</td>\n",
              "      <td>0.772417</td>\n",
              "      <td>5.923637</td>\n",
              "      <td>6.164980</td>\n",
              "      <td>2</td>\n",
              "      <td>cuda</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>1.489562</td>\n",
              "      <td>0.493483</td>\n",
              "      <td>6.389271</td>\n",
              "      <td>6.580999</td>\n",
              "      <td>1</td>\n",
              "      <td>cuda</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "      <td>1.387307</td>\n",
              "      <td>0.506817</td>\n",
              "      <td>12.479754</td>\n",
              "      <td>12.710398</td>\n",
              "      <td>1</td>\n",
              "      <td>cpu</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>69</td>\n",
              "      <td>1</td>\n",
              "      <td>1.309176</td>\n",
              "      <td>0.566733</td>\n",
              "      <td>5.956735</td>\n",
              "      <td>6.205655</td>\n",
              "      <td>2</td>\n",
              "      <td>cuda</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>1.359743</td>\n",
              "      <td>0.522933</td>\n",
              "      <td>12.427641</td>\n",
              "      <td>12.725702</td>\n",
              "      <td>2</td>\n",
              "      <td>cpu</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>71</td>\n",
              "      <td>1</td>\n",
              "      <td>1.390666</td>\n",
              "      <td>0.519267</td>\n",
              "      <td>6.050465</td>\n",
              "      <td>6.453669</td>\n",
              "      <td>4</td>\n",
              "      <td>cuda</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    run  epoch      loss  accuracy  ...  num_workers  device      lr batch_size\n",
              "0     1      1  0.559973  0.788717  ...            0    cuda  0.0100        100\n",
              "1     2      1  0.572739  0.783117  ...            0     cpu  0.0100        100\n",
              "2     3      1  0.567751  0.785667  ...            1    cuda  0.0100        100\n",
              "3     4      1  0.563203  0.785683  ...            1     cpu  0.0100        100\n",
              "4     5      1  0.599108  0.772417  ...            2    cuda  0.0100        100\n",
              "..  ...    ...       ...       ...  ...          ...     ...     ...        ...\n",
              "66   67      1  1.489562  0.493483  ...            1    cuda  0.0001        100\n",
              "67   68      1  1.387307  0.506817  ...            1     cpu  0.0001        100\n",
              "68   69      1  1.309176  0.566733  ...            2    cuda  0.0001        100\n",
              "69   70      1  1.359743  0.522933  ...            2     cpu  0.0001        100\n",
              "70   71      1  1.390666  0.519267  ...            4    cuda  0.0001        100\n",
              "\n",
              "[71 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Run(lr=0.0001, batch_size=100, num_workers=4, device='cpu')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-2409a38fb20f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mrunManger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    group['eps'])\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCFNNbUPyd0_"
      },
      "source": [
        "在这里，我们可以看到cuda设备的性能比cpu高出2倍至3倍。 结果可能会有所不同。"
      ]
    }
  ]
}