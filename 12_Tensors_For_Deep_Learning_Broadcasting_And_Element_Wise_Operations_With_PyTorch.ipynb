{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12_Tensors For Deep Learning - Broadcasting And Element-Wise Operations With PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpW24haoYwN05NE1sMBfTU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YinGuoX/Deep_Learning_Pytorch_WithDeeplizard/blob/master/12_Tensors_For_Deep_Learning_Broadcasting_And_Element_Wise_Operations_With_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtnUxDGQd42j"
      },
      "source": [
        "# Element-Wise Tensor Operations For Deep Learning\n",
        "\n",
        " 在这篇文章中，我们将通过学习元素操作来扩展我们的知识，而不仅仅是重塑操作。\n",
        "\n",
        "\n",
        "## 1. 元素操作意味着？\n",
        "\n",
        "在神经网络编程中，基于元素的操作是非常常见的带有张量的操作。 让我们以元素操作的定义开始讨论：\n",
        "\n",
        "逐个元素的操作是两个张量之间的操作，该操作在各个张量内的相应元素上进行。\n",
        "\n",
        "如果两个元素在张量中占据相同的位置，则称这两个元素是对应的。位置由用于定位每个元素的索引确定。\n",
        "\n",
        "假设我们有以下两个张量：\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVp9W7-sd2_l"
      },
      "source": [
        "import torch\n",
        "t1 = torch.tensor([\n",
        "    [1,2],\n",
        "    [3,4]\n",
        "], dtype=torch.float32)\n",
        "\n",
        "t2 = torch.tensor([\n",
        "    [9,8],\n",
        "    [7,6]\n",
        "], dtype=torch.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTcri2tTfKRR"
      },
      "source": [
        "这两个张量均为2 x 2形状的rank-2张量。\n",
        "\n",
        "这意味着我们有两个轴，每个轴的长度均为两个元素。 第一轴的元素是数组，第二轴的元素是数字。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEnMA3kde2vj",
        "outputId": "089b3890-1892-40f9-ff5f-75266dccc02e"
      },
      "source": [
        "print(t1[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq8fKlWufPpz",
        "outputId": "896e3094-347f-4552-df03-b2262c9aa85f"
      },
      "source": [
        "print(t1[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NafGzVELfWVx"
      },
      "source": [
        "这是我们现在在本系列中经常看到的那种东西。 好吧，让我们以此为基础。\n",
        "\n",
        "我们知道，如果两个元素在张量内处于相同位置，则认为这两个元素是对应的，并且该位置由用于定位每个元素的索引确定。 让我们看一个对应元素的例子。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LWhjCRFfRhi",
        "outputId": "14d4ddf0-8f77-4970-dd3b-028cdf60c6c0"
      },
      "source": [
        "t1[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTG1JwFQfYbE",
        "outputId": "2e3bc6af-3480-44f4-f2ac-ba39d3ef3756"
      },
      "source": [
        "t2[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C82SR4lVfgGx"
      },
      "source": [
        "这使我们看到t1中1的对应元素是t2中9的元素。\n",
        "\n",
        "对应关系由索引定义。 这很重要，因为它揭示了元素方式操作的重要特征。 我们可以推断出张量必须具有相同数量的元素才能执行逐个元素的操作。\n",
        "\n",
        "我们将继续进行此声明，使其更具限制性。 两个张量必须具有相同的形状，以便对其执行按元素的操作。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaZg8M9Pfquq"
      },
      "source": [
        "### 元素加法\n",
        "  --- \n",
        "让我们看一下我们第一个基于元素的操作加法。 不用担心 它将变得更加有趣。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEtvr2wFfaey",
        "outputId": "5edd26f0-1db9-46da-e801-2c39452d4a16"
      },
      "source": [
        "t1+t2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 10.],\n",
              "        [10., 10.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_b-5x-Xf5XZ"
      },
      "source": [
        "这让我们看到张量之间的加法是一种元素操作。在相应位置的每一对元素被加在一起产生一个相同形状的新张量。\n",
        "\n",
        "所以，加法是一种逐元素运算，实际上，所有的算术运算，加、减、乘、除都是逐元素运算。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvGHjiRqgFXx"
      },
      "source": [
        "## 2. 元素操作的算术运算\n",
        "我们通常用张量看到的运算是使用标量值的算术运算。 我们可以通过两种方式执行此操作：\n",
        "\n",
        "### 通过运算符进行算术运算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd9HbvwEfzUS",
        "outputId": "41372273-9d88-4e3d-99d4-75dd58e0b182"
      },
      "source": [
        "print(t1)\n",
        "print(t2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "tensor([[9., 8.],\n",
            "        [7., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_SUhcpfgUPy",
        "outputId": "59127b7e-ffb0-46b2-be0f-3bc6210639f6"
      },
      "source": [
        "print(t1+2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 4.],\n",
            "        [5., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPiKWeregYbi",
        "outputId": "7f2c1a71-8a3a-4d97-ba7d-7ca8d8901a8d"
      },
      "source": [
        "print(t1-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.,  0.],\n",
            "        [ 1.,  2.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi81q0DKgZsQ",
        "outputId": "ef5e1484-448d-4a31-923e-12662129c4dc"
      },
      "source": [
        "print(t1*2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fctQalZGgbZx",
        "outputId": "e3d749d6-9a0e-4a45-9fe9-044ecb3b1d33"
      },
      "source": [
        "print(t1/2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5000, 1.0000],\n",
            "        [1.5000, 2.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot9zEI-4geOy"
      },
      "source": [
        "### 通过内置函数进行算术运算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vghcGZc2gcdR",
        "outputId": "0809395a-a632-4407-b0e2-d82c9c2896d2"
      },
      "source": [
        "print(t1.add(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 4.],\n",
            "        [5., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chcQxY5TglMS",
        "outputId": "671fb10b-acd0-44b4-8f67-273d5c2b63b8"
      },
      "source": [
        "print(t1.sub(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.,  0.],\n",
            "        [ 1.,  2.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9X5RK70gm4C",
        "outputId": "989ec61f-8de9-499c-e127-e48f629076d4"
      },
      "source": [
        "print(t1.mul(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suNiiofLgo8x",
        "outputId": "f283ce7f-debc-42e7-cf10-a9a57c5e19f8"
      },
      "source": [
        "print(t1.div(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5000, 1.0000],\n",
            "        [1.5000, 2.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgG_HLxDgzBQ"
      },
      "source": [
        "这两个选项的工作原理相同。 我们可以看到，在两种情况下，标量值2均通过相应的算术运算应用于每个元素。\n",
        "\n",
        "这里似乎有些问题。 这些例子打破了我们建立的规则，即所述基于元素的运算在相同形状的张量上进行操作。\n",
        "\n",
        "标量值是Rank-0张量，这意味着它们没有形状，而我们的张量t1是形状2 x 2的rank-2张量。\n",
        "\n",
        "那么这如何适合呢？ 让我们分析一下。\n",
        "\n",
        "可能想到的第一个解决方案是，该操作仅使用单个标量值并对张量内的每个元素进行操作。\n",
        "\n",
        "这种逻辑的作品。 但是，这有点让人误解，并且在我们注意到使用标量的更一般的情况下，它会崩溃。\n",
        "\n",
        "为了不同地考虑这些操作，我们需要引入张量广播或广播的概念。\n",
        "\n",
        "### 广播张量\n",
        "  ---\n",
        "广播描述了不同形状的张量在元素操作中的处理方式。\n",
        "\n",
        "广播是一个概念，它的实现允许我们向高维张量添加标量。\n",
        "\n",
        "让我们考虑一下t1+2操作。这里，标量值张量被广播到t1的形状，然后，执行元素操作。\n",
        "\n",
        "我们可以使用broadcast_to()函数查看广播标量值的外观："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXpTIa0Fgq5R",
        "outputId": "8428b5f8-33a7-4bdd-e0de-173f7e43ee62"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.broadcast_to(2,t1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 2],\n",
              "       [2, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNdCCLSshgZx"
      },
      "source": [
        "代码的意思是，将标量值像t1一样转换为rank-2张量，正好那样就形状匹配，并且具有相同形状的元素方式规则又重新发挥了作用。 当然，这全都在幕后。\n",
        "\n",
        "也即是："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3AH1fHnhXEz",
        "outputId": "20e2e6ff-922b-4b30-fac1-3592c56632ff"
      },
      "source": [
        "t1+2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 4.],\n",
              "        [5., 6.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aayvE-F0hueA"
      },
      "source": [
        "事实上就是："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE06jhVXhtvD",
        "outputId": "494b9069-81c0-49f9-8828-1d4f00349e35"
      },
      "source": [
        "t1+torch.tensor(np.broadcast_to(2,t1.shape),dtype=torch.float32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 4.],\n",
              "        [5., 6.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KopMKrEh8Wx"
      },
      "source": [
        "在这一点上，您可能会认为这似乎令人费解，所以让我们看一个更棘手的例子来说明这一点。 \n",
        "\n",
        "### 一个更棘手的广播操作\n",
        "假设我们有以下两个张量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUJELLJGh4MC"
      },
      "source": [
        "t1 = torch.tensor([\n",
        "    [1,1],\n",
        "    [1,1]\n",
        "], dtype=torch.float32)\n",
        "\n",
        "t2 = torch.tensor([2,4], dtype=torch.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYYOKaaPiU8Z"
      },
      "source": [
        "这个元素加法运算的结果是什么？对于元素操作，是否有可能给定相同的形状规则？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3NQn-ZTiRPC",
        "outputId": "04ec67f0-940b-4aa0-8ffb-47a5d85dba0e"
      },
      "source": [
        "t1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV1-XpCLiXFC",
        "outputId": "d26f04fc-f499-48c5-cef8-b9310fbbcaef"
      },
      "source": [
        "t2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvMB06KCigCZ"
      },
      "source": [
        "尽管这两个张量有着不同的形状，但元素的操作是可能的，而广播则使操作成为可能。低秩张量t2将通过广播变换以匹配高秩张量t1的形状，并且将照常执行元素操作。\n",
        "\n",
        "广播的概念是理解如何开展这项行动的关键。和前面一样，我们可以使用broadcast_to()函数检查广播转换。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp4d2WZBiYCC",
        "outputId": "035b5591-b192-4d6a-a498-cbd26aa8dbad"
      },
      "source": [
        "np.broadcast_to(t2.numpy(),t1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2., 4.],\n",
              "       [2., 4.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IprJc7gxip62",
        "outputId": "81a7b15f-0ae0-45f7-d85e-d7c211e83b10"
      },
      "source": [
        "t1+t2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 5.],\n",
              "        [3., 5.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLwXZLVAivpQ"
      },
      "source": [
        "广播后，这两个张量之间的加法运算是相同形状的张量之间的常规按元素运算。\n",
        "\n",
        "[此文章](https://deeplizard.com/learn/video/6_33ulFDuCg)具有更详细的广播操作的讲解，请自行查阅。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en8Ie2d_jZ4Z"
      },
      "source": [
        "## 2. 比较操作\n",
        "比较操作也是按元素进行的操作。\n",
        "\n",
        "对于两个张量之间的给定比较操作，将返回一个具有相同形状的新张量，其中每个元素都包含torch.bool值为True或False的元素。\n",
        "\n",
        "PyTorch版本1.2.0中的行为更改\n",
        "\n",
        "比较操作返回的数据类型已从更改为torch.uint8至torch.bool([21113](https://github.com/pytorch/pytorch/pull/21113)).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmgqWAsfitYi",
        "outputId": "d534e3eb-c53e-43d8-b2f0-1efd97efbf6b"
      },
      "source": [
        "torch.tensor([1,2,3])>torch.tensor([3,1,2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji2MR6dVkDE5"
      },
      "source": [
        "### 一些比较操作的例子\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_9g94wnj-0y"
      },
      "source": [
        "t = torch.tensor([\n",
        "    [0,5,0],\n",
        "    [6,0,7],\n",
        "    [0,8,0]\n",
        "], dtype=torch.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfueW7SYkKjC",
        "outputId": "f595cbc0-3ef6-4a47-ff52-97f2d736e188"
      },
      "source": [
        "t.eq(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True, False,  True],\n",
              "        [False,  True, False],\n",
              "        [ True, False,  True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79NBccTbkMQB",
        "outputId": "a6ab2d4c-b31c-47ce-dd61-b5fde7691d9a"
      },
      "source": [
        "t.ge(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True],\n",
              "        [True, True, True],\n",
              "        [True, True, True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdYuwOd2kNix",
        "outputId": "2fd6d6fe-b053-44c6-81a1-7aa49e1b7749"
      },
      "source": [
        "t.gt(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True, False],\n",
              "        [ True, False,  True],\n",
              "        [False,  True, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Om5-tspkPsR",
        "outputId": "37254fb2-e657-43c1-d936-6e210b1fd867"
      },
      "source": [
        "t.lt(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False],\n",
              "        [False, False, False],\n",
              "        [False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aakIK7v1kVLS",
        "outputId": "9a7b4e22-abe1-4864-f704-e89a6dd6fd2a"
      },
      "source": [
        "t.le(7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True,  True,  True],\n",
              "        [ True,  True,  True],\n",
              "        [ True, False,  True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMQ1hqI8kZ0C"
      },
      "source": [
        "从广播的角度考虑这些操作，我们可以看到最后一个t.le（7）实际上是这样的："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STR_lgWbkWlR",
        "outputId": "2cd7c225-7cc6-4083-f5c6-1f32b8c9f849"
      },
      "source": [
        "t <= torch.tensor(np.broadcast_to(7,t.shape),dtype=torch.float32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True,  True,  True],\n",
              "        [ True,  True,  True],\n",
              "        [ True, False,  True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIjieGEhkmVh"
      },
      "source": [
        "等同于"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KcS8XXQkjDC"
      },
      "source": [
        "t <= torch.tensor([\n",
        "    [7,7,7],\n",
        "    [7,7,7],\n",
        "    [7,7,7]\n",
        "], dtype=torch.float32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeL2UHybks6I"
      },
      "source": [
        "## 3.一些元素操作的函数\n",
        "使用作为函数的按元素操作，可以很好地假定该函数应用于张量的每个元素。\n",
        "\n",
        "这里有些例子："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZFrxprckw3S",
        "outputId": "ee3a2411-42b2-484f-df95-a168f694cdb9"
      },
      "source": [
        "t.abs()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 5., 0.],\n",
              "        [6., 0., 7.],\n",
              "        [0., 8., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjAnKY1qk2GT",
        "outputId": "f29a2514-5a12-46b4-b52e-1dbab6ad75b4"
      },
      "source": [
        "t.sqrt()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 2.2361, 0.0000],\n",
              "        [2.4495, 0.0000, 2.6458],\n",
              "        [0.0000, 2.8284, 0.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TXa0DV_k3dT",
        "outputId": "7afd32de-b3fe-4b9f-b5e6-959813f54f41"
      },
      "source": [
        "t.neg()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0., -5., -0.],\n",
              "        [-6., -0., -7.],\n",
              "        [-0., -8., -0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV2IB7muk4ch",
        "outputId": "d0f3265c-719c-446d-e348-71db25b8bb84"
      },
      "source": [
        "t.neg().abs()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 5., 0.],\n",
              "        [6., 0., 7.],\n",
              "        [0., 8., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-85wR5YlC-R"
      },
      "source": [
        "一些术语\n",
        "\n",
        "还有一些其他的方法来引用元素类型的操作，所以我只想提一下，所有这些操作的意思都是一样的:\n",
        "\n",
        "* Element-wise\n",
        "* Component-wise\n",
        "* Point-wise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mPRsuOwk7Xh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}