{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_Rank, Axes, And Shape Explained - Tensors For Deep Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOHtgxWHDJ9sIOxZyiqe9hr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YinGuoX/Deep_Learning_Pytorch_WithDeeplizard/blob/master/6_Rank%2C_Axes%2C_And_Shape_Explained_Tensors_For_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXnrlSXMeQhK"
      },
      "source": [
        "# Rank, Axes And Shape - Tensors For Deep Learning\n",
        "在本文中，我们将更深入地研究张量，并介绍三个基本的张量属性，即rank，axes和shape。 事不宜迟，让我们开始吧\n",
        "\n",
        "Rank、Axes、Shape等概念是深学习中最关心的张量属性。\n",
        "\n",
        "秩、轴和形状是三个张量属性，当我们在深度学习中开始使用张量时，它们将是我们最关心的。这些概念是建立在一个又一个的基础上的，先是等级，然后是轴，最后是形状，所以请注意这三者之间的关系。\n",
        "\n",
        "## 1.Tensor的Rank\n",
        "**张量的秩是指张量中存在的维数**。\n",
        "\n",
        "假设我们被告知有一个秩2张量。这意味着以下所有情况：\n",
        "* 一个矩阵\n",
        "* 一个二维数组\n",
        "* 一个二维张量\n",
        "我们在这里引入rank这个词是因为它通常用于深度学习，指的是给定张量中的维数。这只是另一个例子，不同的研究领域使用不同的词来指代同一个概念。别让它把你甩了！\n",
        "\n",
        "**Rank and Indexs**：\n",
        "* 张量的rank告诉我们需要多少个索引来引用张量内的特定元素\n",
        "* A tensor's rank tells us how many indexes are needed to refer to a specific element within the tensor.\n",
        "\n",
        "## 2.Tensor的Axes\n",
        "\n",
        "**张量的轴是张量的一个特定维度。**\n",
        "\n",
        "如果我们有一个张量，并且想要引用一个特定的维，则在深度学习中使用Axes来表示特定的维。\n",
        "\n",
        "如果我们说张量是rank 2 张量，则意味着张量具有2个维度，或者等效地，张量具有2个轴。\n",
        "\n",
        "\n",
        "**Length Of An Axis**：\n",
        "\n",
        "* 每个轴的长度告诉我们沿每个轴有多少索引可用。\n",
        "\n",
        "假设我们有一个名为t的张量，并且我们知道第一个轴的长度为3，而第二个轴的长度为4。由于第一轴的长度为三，这意味着我们可以沿第一轴索引三个位置。因为第二个轴有四个长度，我们可以沿着第二个轴索引四个位置。这对于第一轴的每个索引都是可能的。\n",
        "\n",
        "一个例子："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GueaIPQKeN0D"
      },
      "source": [
        "t = [\n",
        "     [1,2,3],\n",
        "     [4,5,6],\n",
        "     [7,8,9]\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbdzjtJthK04",
        "outputId": "b471b89c-0400-40ad-b7f0-5a7506983838"
      },
      "source": [
        "t[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT4CH3e7hMVi",
        "outputId": "4d5b09ee-8e40-4e19-b441-29993ade0dd0"
      },
      "source": [
        "t[0][0],t[0][1],t[0][2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFpJ9VRnhkk5"
      },
      "source": [
        "所以：张量的rank告诉我们一个张量有多少个Axes，这些Axes的长度使我们引出一个非常重要的概念，即张量的形状。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlQAxBK-hp9Y"
      },
      "source": [
        "## 3. Tensor的Shape\n",
        "**张量的形状为我们提供了每个张量轴的长度。**\n",
        "\n",
        "例子："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JqzCZkghRpy",
        "outputId": "86bd604e-dba4-4dd5-c419-ab73bf4d02bf"
      },
      "source": [
        "import torch\n",
        "dd = [\n",
        "[1,2,3],\n",
        "[4,5,6],\n",
        "[7,8,9]\n",
        "]\n",
        "\n",
        "t = torch.tensor(dd)\n",
        "t.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IaYkNL7iTHw"
      },
      "source": [
        "这使我们可以看到张量的形状为3 x3。请注意，在PyTorch中，张量的大小和形状是相同的,也即size==shape。\n",
        "\n",
        "3 x 3的形状告诉我们，该秩为2的张量的每个轴的长度为3，这意味着我们在每个轴上都可以使用三个索引。 现在让我们看一下为什么张量的形状如此重要。\n",
        "\n",
        "**Shape的重要性：**\n",
        "* 1.因为形状使我们可以从概念上考虑甚至可视化张量。高等级的张量变得更加抽象，并且形状使我们有一些具体的思考的地方。\n",
        "* 2.形状还对有关Axes，Rank和索引的所有相关信息进行编码。\n",
        "* 3.在对神经网络进行编程时必须经常执行的一种操作类型称为reshaping。当我们的张量流过我们的网络时，期望在网络内部的不同点出现某些形状，而作为神经网络程序员，我们需要了解传入的形状并具有根据需要进行重塑。\n",
        "\n",
        "**Tensor的Reshaping:**\n",
        "看例子理解！"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ciil1nFmlG22",
        "outputId": "4a6c9d51-c118-46f7-aece-247897622cc7"
      },
      "source": [
        "d = torch.tensor([1,2,3])\n",
        "d.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfqDou3PiEiB",
        "outputId": "066883dd-d8a2-4069-8ea5-555803502289"
      },
      "source": [
        "t = torch.tensor(dd)\n",
        "t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvoJB_0Hjh6-"
      },
      "source": [
        "此张量是rank为2的张量，shape为[3,3]或3 x 3,此时是第一个轴有3个数组，并沿第二个轴有3个数字。\n",
        "\n",
        "现在我们将其reshape成[1,9]：这将使我们沿第一个轴具有一个数组，并沿第二个轴具有九个数字："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNsqIX_tjd3R",
        "outputId": "df7aa3ee-e161-4332-c28d-45bf3c7ee55f"
      },
      "source": [
        "t= t.reshape(1,9)\n",
        "t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snpltulfkX6i",
        "outputId": "6e9e4d09-98b2-4dcf-f99e-4c85efd9cd74"
      },
      "source": [
        "t.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUpqKTkYkhY5"
      },
      "source": [
        "要注意的一点是，形状中的组件值的乘积必须等于张量中元素的总数。这样可以使张量数据结构内有足够的位置，以在重塑后包含所有原始数据元素。\n",
        "\n",
        "* 重塑会更改形状，但不会更改基础数据元素。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDst-y2OkcuB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}